{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator._hyperparameters['sagemaker_job_name'] = 'kanto-job-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sagemaker_job_name': 'kanto-base-job-2020-08-22-02-01-56-986',\n",
       " 'sagemaker_submit_directory': 's3://sagemaker-ap-northeast-2-029498593638/kanto-base-job-2020-08-22-02-01-56-986/source/sourcedir.tar.gz',\n",
       " 'sagemaker_program': 'HRC_0818_final.py',\n",
       " 'sagemaker_enable_cloudwatch_metrics': False,\n",
       " 'sagemaker_container_log_level': 20,\n",
       " 'sagemaker_region': 'ap-northeast-2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_estimator._hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator = PyTorch(entry_point='HRC_0818_final.py',\n",
    "                            train_instance_type='ml.m4.xlarge',\n",
    "                            role=role,\n",
    "                            train_instance_count=1,\n",
    "                            framework_version='1.4.0',\n",
    "                            #output_path = 's3://{}/{}/model-output',\n",
    "                            base_job_name = 'step-test'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-22 04:14:35 Starting - Starting the training job...\n",
      "2020-08-22 04:14:39 Starting - Launching requested ML instances......\n",
      "2020-08-22 04:15:47 Starting - Preparing the instances for training......\n",
      "2020-08-22 04:16:45 Downloading - Downloading input data...\n",
      "2020-08-22 04:17:30 Training - Downloading the training image...\n",
      "2020-08-22 04:18:00 Uploading - Uploading generated training model\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:51,501 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:51,505 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:51,517 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:51,731 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:52,052 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:52,053 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:52,053 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:52,053 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpd895wm_e/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=10275 sha256=5d5404006fe5ee7e5cff35771a38fff90196ede0e3a91af22e1f77ad1caada6e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2jtdyw5s/wheels/44/6d/a7/10c4f5ce54a6fcb5f5b6b5076f2d9780518f9d3c2163d3deaf\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:54,888 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:54,904 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:54,918 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:54,932 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"step-fit\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-029498593638/step-fit/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"HRC_0818_final\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"HRC_0818_final.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=HRC_0818_final.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=HRC_0818_final\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-029498593638/step-fit/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"step-fit\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-029498593638/step-fit/source/sourcedir.tar.gz\",\"module_name\":\"HRC_0818_final\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"HRC_0818_final.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python HRC_0818_final.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 47/47 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 47/47 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.856 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.856 algo-1:44 INFO hook.py:191] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.856 algo-1:44 INFO hook.py:236] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.856 algo-1:44 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.857 algo-1:44 INFO hook.py:376] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:58.858 algo-1:44 INFO hook.py:437] Hook is writing from the hook with pid: 44\n",
      "\u001b[0m\n",
      "\u001b[34mAnomaly score 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 7.2870307, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016, 0.070050016\u001b[0m\n",
      "\u001b[34mAnomaly score 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 7.2794747, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987, 0.06875987\u001b[0m\n",
      "\u001b[34mAnomaly score 0.067436926, 7.272035, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926, 0.067436926\u001b[0m\n",
      "\u001b[34mAnomaly score 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 7.26519, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642, 0.06618642\u001b[0m\n",
      "\u001b[34mAnomaly score 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 7.259899, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717, 0.06505717\u001b[0m\n",
      "\u001b[34mAnomaly score 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 7.2564416, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235, 0.064041235\u001b[0m\n",
      "\u001b[34mAnomaly score 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 7.254601, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258, 0.06309258\u001b[0m\n",
      "\u001b[34mAnomaly score 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 7.2640624, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366, 0.062217366\u001b[0m\n",
      "\u001b[34mAnomaly score 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 7.267372, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104, 0.061460104\u001b[0m\n",
      "\u001b[34mAnomaly score 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 7.2621922, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686, 0.060945686\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m[2020-08-22 04:17:59.036 algo-1:44 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-08-22 04:17:59,271 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-08-22 04:18:08 Completed - Training job completed\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n"
     ]
    }
   ],
   "source": [
    "pytorch_estimator.fit('s3://{}/hrms/train/train.jsonl'.format(bucket),job_name='step-fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpi7w4a7iy_algo-1-ii0wl_1\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:48,782 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m MMS Home: /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Number of CPUs: 4\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Max heap size: 3566 M\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Python executable: /opt/conda/bin/python\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Management address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Default workers per model: 4\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:48,856 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:48,877 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,022 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,050 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,091 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,091 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]36\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,092 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,092 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.10\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,101 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,114 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,115 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]33\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,116 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,116 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,117 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.10\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,127 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,150 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,151 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]39\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,152 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,152 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,152 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.10\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,153 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,154 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,166 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,167 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]34\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,168 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,168 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,171 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.10\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:49,176 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:51,193 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2021\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:51,193 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2020\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:51,198 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2013\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:51,223 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2034\n",
      "\u001b[36malgo-1-ii0wl_1  |\u001b[0m 2020-08-22 02:42:51,260 [INFO ] pool-1-thread-5 ACCESS_LOG - /172.18.0.1:43336 \"GET /ping HTTP/1.1\" 200 13\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_estimator.deploy(instance_type='local',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepfunctions\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import s3_input\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.steps import TrainingStep, ModelStep\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "stepfunctions.set_stream_logger(level=logging.INFO)\n",
    "id = uuid.uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_input = ExecutionInput(schema={\n",
    "    'ModelName': str,\n",
    "    'TrainTargetLocation':str,\n",
    "    'TrainingJobName':str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step-fit'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = steps.TrainingStep(\n",
    "    'Model Training', \n",
    "    estimator=pytorch_estimator,\n",
    "    data={\n",
    "         'training': s3_input(s3_data=execution_input['TrainTargetLocation'])\n",
    "    } ,\n",
    "    job_name=execution_input['TrainingJobName'],\n",
    "    wait_for_completion=True\n",
    ")\n",
    "\n",
    "\n",
    "model_step = steps.ModelStep(\n",
    "    'Create model',\n",
    "    model=training_step.get_expected_model(),\n",
    "    model_name=execution_input['ModelName'] ,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_state_training= steps.states.Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=model_step\n",
    ")\n",
    "\n",
    "training_step.add_catch(catch_state_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_definition = steps.Chain([\n",
    "    training_step,\n",
    "    model_step\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_execution_role = 'arn:aws:iam::029498593638:role/StepFunctionsWorkflowExecutionRole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Workflow(\n",
    "    name='training_pipeline_kanto_another',\n",
    "    definition=workflow_definition,\n",
    "    role=workflow_execution_role,\n",
    "    execution_input=execution_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-178\" class=\"workflowgraph\">\n",
       "    \n",
       "    <svg></svg>\n",
       "    \n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var element = document.getElementById('graph-178')\n",
       "\n",
       "    var options = {\n",
       "        width: parseFloat(getComputedStyle(element, null).width.replace(\"px\", \"\")),\n",
       "        height: 600,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Model Training\", \"States\": {\"Model Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification\": {\"TrainingImage\": \"763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-training:1.4.0-cpu-py3\", \"TrainingInputMode\": \"File\"}, \"OutputDataConfig\": {\"S3OutputPath\": \"s3://sagemaker-ap-northeast-2-029498593638/\"}, \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 86400}, \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m4.xlarge\", \"VolumeSizeInGB\": 30}, \"RoleArn\": \"arn:aws:iam::029498593638:role/service-role/AmazonSageMaker-ExecutionRole-20190920T225690\", \"InputDataConfig\": [{\"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri.$\": \"$$.Execution.Input['TrainTargetLocation']\", \"S3DataDistributionType\": \"FullyReplicated\"}}, \"ChannelName\": \"training\"}], \"HyperParameters\": {\"sagemaker_job_name\": \"\\\"kanto-base-job-2020-08-22-04-03-57-957\\\"\", \"sagemaker_submit_directory\": \"\\\"s3://sagemaker-ap-northeast-2-029498593638/kanto-base-job-2020-08-22-04-03-57-866/source/sourcedir.tar.gz\\\"\", \"sagemaker_program\": \"\\\"HRC_0818_final.py\\\"\", \"sagemaker_enable_cloudwatch_metrics\": \"false\", \"sagemaker_container_log_level\": \"20\", \"sagemaker_region\": \"\\\"ap-northeast-2\\\"\"}, \"TrainingJobName.$\": \"$$.Execution.Input['TrainingJobName']\", \"DebugHookConfig\": {\"S3OutputPath\": \"s3://sagemaker-ap-northeast-2-029498593638/\", \"CollectionConfigurations\": []}}, \"Type\": \"Task\", \"Next\": \"Create model\", \"Catch\": [{\"ErrorEquals\": [\"States.TaskFailed\"], \"Next\": \"Create model\"}]}, \"Create model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['ModelName']\", \"PrimaryContainer\": {\"Image\": \"763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/pytorch-inference:1.4.0-cpu-py3\", \"Environment\": {\"SAGEMAKER_PROGRAM\": \"HRC_0818_final.py\", \"SAGEMAKER_SUBMIT_DIRECTORY\": \"s3://sagemaker-ap-northeast-2-029498593638/kanto-base-job-2020-08-22-04-03-57-866/source/sourcedir.tar.gz\", \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\", \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\", \"SAGEMAKER_REGION\": \"ap-northeast-2\"}, \"ModelDataUrl.$\": \"$['ModelArtifacts']['S3ModelArtifacts']\"}, \"ExecutionRoleArn\": \"arn:aws:iam::029498593638:role/service-role/AmazonSageMaker-ExecutionRole-20190920T225690\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-178';\n",
       "\n",
       "    var graph = new sfn.StateMachineGraph(definition, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.render_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] Workflow created successfully on AWS Step Functions.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:ap-northeast-2:029498593638:stateMachine:training_pipeline_kanto_another'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
